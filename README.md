# llama-2-70b-chat-agent

This is copied from github/pinecone-io repo

Modified original model to use 7b instead of 7b, trial

Chat results were very similar with the 7b model

This will be run in Google Colab due to the GPU requirements